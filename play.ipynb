{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with AViT\n",
    "\n",
    "Use AViT (ViT-B based) as an example. Load the model weights, and test the model on the 4th folder of the ISIC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "from Utils.pieces import DotDict\n",
    "from os.path import join\n",
    "from Datasets.create_dataset import Dataset_wrap_csv\n",
    "import medpy.metric.binary as metrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_PATH = '/ubc/ece/home/ra/grads/siyi/Research/skin_lesion_segmentation/results/ISICW/K_results/K3_ISIC/ca_R34_v4_isic2018_ViTSeg_CNNprompt_adapt_20230508_1840'\n",
    "dataset_name = 'isic2018'\n",
    "config_yml = join(EXP_PATH, 'exp_config.yml')\n",
    "ckpt_path = join(EXP_PATH, 'best.pth')\n",
    "config = yaml.load(open(config_yml), Loader=yaml.FullLoader)\n",
    "config = DotDict(config)\n",
    "config.data.data_folder = '/bigdata/siyiplace/data/skin_lesion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bigdata/siyiplace/data/skin_lesion/isic2018/\n",
      "isic2018 has 2594 samples, 2076 are used to train, 518 are used to test. \n",
      " 5 Folder -- Use 4\n"
     ]
    }
   ],
   "source": [
    "datas = Dataset_wrap_csv(k_fold=config.data.k_fold, use_old_split=True, img_size=config.data.img_size, \n",
    "    dataset_name = dataset_name, split_ratio=config.data.split_ratio, \n",
    "    train_aug=config.data.train_aug, data_folder=config.data.data_folder)\n",
    "train_data, val_data, test_data = datas['train'], datas['test'], datas['test']\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                        batch_size=config.train.batch_size,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=config.train.num_workers,\n",
    "                                        pin_memory=True,\n",
    "                                        drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                        batch_size=config.test.batch_size,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=config.test.num_workers,\n",
    "                                        pin_memory=True,\n",
    "                                        drop_last=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                        batch_size=config.test.batch_size,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=config.test.num_workers,\n",
    "                                        pin_memory=True,\n",
    "                                        drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.model == 'ViTSeg_CNNprompt_adapt':\n",
    "    from Models.Transformer.ViT_adapters import ViTSeg_CNNprompt_adapt\n",
    "    model = ViTSeg_CNNprompt_adapt(pretrained=False, pretrained_vit_name=config.vit.name,\n",
    "    pretrained_folder=config.pretrained_folder,img_size=config.data.img_size, patch_size=config.vit.patch_size,\n",
    "    embed_dim=config.vit.embed_dim, depth=config.vit.depth, num_heads=config.vit.num_heads, \n",
    "    mlp_ratio=config.vit.mlp_ratio, drop_rate=config.vit.dropout_rate, \n",
    "    attn_drop_rate=config.vit.attention_dropout_rate, drop_path_rate=0.2, \n",
    "    debug=config.debug, adapt_method=config.model_adapt.adapt_method, num_domains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(ckpt_path))\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:20<00:00,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isic2018, Dice: 0.9200534490090431, IOU: 0.8558168345745101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "dice_test_sum, iou_test_sum, num_test = 0, 0, 0\n",
    "for batch in tqdm(test_loader):\n",
    "    img = batch['image'].cuda().float()\n",
    "    label = batch['label'].cuda().float()\n",
    "    # domain label\n",
    "    d = '0'  \n",
    "    batch_len = img.shape[0]\n",
    "    with torch.no_grad():\n",
    "        output = model(img,d=d)['seg']\n",
    "        output = torch.sigmoid(output)\n",
    "        # calculate metrics\n",
    "        output = output.cpu().numpy() > 0.5\n",
    "        label = label.cpu().numpy()\n",
    "        dice_test_sum += metrics.dc(output, label)*batch_len\n",
    "        iou_test_sum += metrics.jc(output, label)*batch_len\n",
    "        num_test += batch_len\n",
    "\n",
    "print(f'{dataset_name}, Dice: {dice_test_sum/num_test}, IOU: {iou_test_sum/num_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skinlesion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
