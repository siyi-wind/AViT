name: 'Experiment on local machine'
# include code and results folders
root_dir: '/ubc/ece/home/ra/grads/siyi/Research/skin_lesion_segmentation'
pretrained_folder: '/bigdata/siyiplace/data/skin_lesion'
device: 'cuda'
# True only train, test one batch
debug: False
data:
  # ['isic2018', 'PH2', 'DMF', 'SKD']
  name: ['isic2018', 'PH2', 'DMF', 'SKD']
  data_folder: '/bigdata/siyiplace/data/skin_lesion'
  k_fold: '4'
  split_ratio: [0.8, 0.2]
  use_val: False  # if false, combine train and val sets to train
  train_aug: True
  img_size: 224
train:
  num_workers: 6
  num_epochs: 200
  num_iters: False # num of updating for each epoch
  # batch_size uses args to define
  optimizer:
    mode: 'adamw'
    adamw:
      lr: '1e-4'
      betas: 
        - 0.9
        - 0.999
      eps: '1e-8'
      weight_decay: 0.05
    adam:
      lr: '1e-4'
      betas:
        - 0.9
        - 0.999
test:
  only_test: False  # if True, only do test
  test_model_dir: '/ubc/ece/home/ra/grads/siyi/Research/skin_lesion_segmentation/results/ISICW/C_results/C65/ca_4base_isic2018_ViTSeg_20230430_1655/best.pth'
  num_workers: 6
  batch_size: 5
# model uses args to define
# resnet[18,34,50,101]
model_encoder_id: 0
model_adapt:
  # MLP  AdaptFormer
  adapt_method: False
  num_domains: 1

swin:
  # name: 'swin_base_patch4_window7_224_in22k'
  # DROP_PATH_RATE: 0.2
  # EMBED_DIM: 128
  # DEPTHS: [ 2, 2, 18, 2 ]
  # NUM_HEADS: [ 4, 8, 16, 32 ]
  # WINDOW_SIZE: 7
  name: 'swin_large_patch4_window7_224_22k'
  DROP_PATH_RATE: 0.2
  EMBED_DIM: 192
  DEPTHS: [2,2,18] #[ 2, 2, 18, 2 ]
  NUM_HEADS: [6,12,24] #[ 4, 8, 16, 32 ]
  WINDOW_SIZE: 7 
vit:
  # name: 'vit_large_patch16_224_in21k'
  # patch_size: 16
  # embed_dim: 1024
  # mlp_ratio: 4.0
  # num_heads: 16
  # depth: 24
  # attention_dropout_rate: 0.0
  # dropout_rate: 0.1
  
  name: 'vit_base_patch16_224_in21k'
  # name: 'mae_pretrain_vit_base'
  patch_size: 16
  embed_dim: 768
  mlp_ratio: 4.0
  num_heads: 12
  depth: 12
  attention_dropout_rate: 0.0
  dropout_rate: 0.0
deit:
  name: 'deit_base_patch16_224-b5f2ef4d'
  # name: 'mae_pretrain_vit_base'
  patch_size: 16
  embed_dim: 768
  mlp_ratio: 4.0
  num_heads: 12
  depth: 12
  attention_dropout_rate: 0.0
  dropout_rate: 0.0